{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Import Dependencies and Load Data"
      ],
      "metadata": {
        "id": "IegzciKnQXVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "TVlgNkqkQjMH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load and Preprocess the Data"
      ],
      "metadata": {
        "id": "Xgn0q_zcRaYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "\n",
        "# Drop non-beneficial ID columns ('EIN', 'NAME')\n",
        "data = data.drop(columns=[\"EIN\", \"NAME\"])\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "data = pd.get_dummies(data)\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = data.drop(columns=[\"IS_SUCCESSFUL\"]).values\n",
        "y = data[\"IS_SUCCESSFUL\"].values\n",
        "\n",
        "# Split the dataset into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "OWgUu-VXRCLU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Optimization Attempts\n",
        "### Attempt 1: Increase Neurons and Add Layers"
      ],
      "metadata": {
        "id": "AOl4moVcRplV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network model\n",
        "model_1 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer with more neurons\n",
        "model_1.add(tf.keras.layers.Dense(units=100, activation=\"relu\", input_dim=len(X_train_scaled[0])))\n",
        "\n",
        "# Second hidden layer with more neurons\n",
        "model_1.add(tf.keras.layers.Dense(units=50, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "model_1.add(tf.keras.layers.Dense(units=25, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "model_1.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model with early stopping to avoid overfitting\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "history_1 = model_1.fit(X_train_scaled, y_train,\n",
        "                        validation_data=(X_test_scaled, y_test),\n",
        "                        epochs=100,\n",
        "                        callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "model_1_loss, model_1_accuracy = model_1.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Attempt 1 - Loss: {model_1_loss}, Accuracy: {model_1_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMoRRzaaRg81",
        "outputId": "0939a320-97d2-4289-bdcc-b40b912c42a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7038 - loss: 0.5940 - val_accuracy: 0.7216 - val_loss: 0.5649\n",
            "Epoch 2/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.5535 - val_accuracy: 0.7220 - val_loss: 0.5571\n",
            "Epoch 3/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5443 - val_accuracy: 0.7297 - val_loss: 0.5563\n",
            "Epoch 4/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7318 - loss: 0.5466 - val_accuracy: 0.7313 - val_loss: 0.5557\n",
            "Epoch 5/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.5403 - val_accuracy: 0.7243 - val_loss: 0.5576\n",
            "Epoch 6/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7398 - loss: 0.5378 - val_accuracy: 0.7310 - val_loss: 0.5513\n",
            "Epoch 7/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.5422 - val_accuracy: 0.7316 - val_loss: 0.5538\n",
            "Epoch 8/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.5440 - val_accuracy: 0.7325 - val_loss: 0.5546\n",
            "Epoch 9/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7319 - loss: 0.5441 - val_accuracy: 0.7261 - val_loss: 0.5546\n",
            "Epoch 10/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7374 - loss: 0.5393 - val_accuracy: 0.7297 - val_loss: 0.5593\n",
            "Epoch 11/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.5416 - val_accuracy: 0.7308 - val_loss: 0.5536\n",
            "215/215 - 0s - 1ms/step - accuracy: 0.7308 - loss: 0.5536\n",
            "Attempt 1 - Loss: 0.5536369681358337, Accuracy: 0.730758011341095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attempt 2: Change Activation Function (tanh) and Increase Epochs"
      ],
      "metadata": {
        "id": "fkQhmT59ShE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network model\n",
        "model_2 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer with 'tanh' activation\n",
        "model_2.add(tf.keras.layers.Dense(units=100, activation=\"tanh\", input_dim=len(X_train_scaled[0])))\n",
        "\n",
        "# Second hidden layer with 'tanh' activation\n",
        "model_2.add(tf.keras.layers.Dense(units=50, activation=\"tanh\"))\n",
        "\n",
        "# Third hidden layer with 'tanh' activation\n",
        "model_2.add(tf.keras.layers.Dense(units=25, activation=\"tanh\"))\n",
        "\n",
        "# Output layer\n",
        "model_2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model with early stopping and increased epochs\n",
        "history_2 = model_2.fit(X_train_scaled, y_train,\n",
        "                        validation_data=(X_test_scaled, y_test),\n",
        "                        epochs=150,\n",
        "                        callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "model_2_loss, model_2_accuracy = model_2.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Attempt 2 - Loss: {model_2_loss}, Accuracy: {model_2_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8THyf2pSp2E",
        "outputId": "7f7f3043-2a8f-4f29-d7d4-96527c3d9992"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.5794 - val_accuracy: 0.7184 - val_loss: 0.5618\n",
            "Epoch 2/150\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.5461 - val_accuracy: 0.7262 - val_loss: 0.5603\n",
            "Epoch 3/150\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7330 - loss: 0.5488 - val_accuracy: 0.7245 - val_loss: 0.5578\n",
            "Epoch 4/150\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.5455 - val_accuracy: 0.7286 - val_loss: 0.5576\n",
            "Epoch 5/150\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.5420 - val_accuracy: 0.7309 - val_loss: 0.5545\n",
            "215/215 - 0s - 1ms/step - accuracy: 0.7309 - loss: 0.5545\n",
            "Attempt 2 - Loss: 0.554459273815155, Accuracy: 0.7309038043022156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attempt 3: Drop Additional Columns (ASK_AMT) to Reduce Noise"
      ],
      "metadata": {
        "id": "6X8q1MtyS8Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop ASK_AMT column to see if it improves performance\n",
        "data_optimized = data.drop(columns=[\"ASK_AMT\"])\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X_opt = data_optimized.drop(columns=[\"IS_SUCCESSFUL\"]).values\n",
        "y_opt = data_optimized[\"IS_SUCCESSFUL\"].values\n",
        "\n",
        "# Split the dataset into training and testing data\n",
        "X_train_opt, X_test_opt, y_train_opt, y_test_opt = train_test_split(X_opt, y_opt, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the data\n",
        "scaler_opt = StandardScaler()\n",
        "X_train_scaled_opt = scaler_opt.fit_transform(X_train_opt)\n",
        "X_test_scaled_opt = scaler_opt.transform(X_test_opt)\n",
        "\n",
        "# Define the neural network model with a simpler architecture\n",
        "model_3 = tf.keras.models.Sequential()\n",
        "model_3.add(tf.keras.layers.Dense(units=80, activation=\"relu\", input_dim=len(X_train_scaled_opt[0])))\n",
        "model_3.add(tf.keras.layers.Dense(units=30, activation=\"relu\"))\n",
        "model_3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history_3 = model_3.fit(X_train_scaled_opt, y_train_opt,\n",
        "                        validation_data=(X_test_scaled_opt, y_test_opt),\n",
        "                        epochs=100,\n",
        "                        callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "model_3_loss, model_3_accuracy = model_3.evaluate(X_test_scaled_opt, y_test_opt, verbose=2)\n",
        "print(f\"Attempt 3 - Loss: {model_3_loss}, Accuracy: {model_3_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-JOVmTGTAhU",
        "outputId": "244478a9-8bea-45fa-ef6b-c0d7bd8b4409"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7005 - loss: 0.5968 - val_accuracy: 0.7226 - val_loss: 0.5607\n",
            "Epoch 2/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7292 - loss: 0.5529 - val_accuracy: 0.7255 - val_loss: 0.5577\n",
            "Epoch 3/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.5485 - val_accuracy: 0.7246 - val_loss: 0.5596\n",
            "Epoch 4/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.5460 - val_accuracy: 0.7278 - val_loss: 0.5580\n",
            "Epoch 5/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.5462 - val_accuracy: 0.7246 - val_loss: 0.5566\n",
            "215/215 - 0s - 1ms/step - accuracy: 0.7246 - loss: 0.5566\n",
            "Attempt 3 - Loss: 0.5566226243972778, Accuracy: 0.7246355414390564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Save the Best Model"
      ],
      "metadata": {
        "id": "zauxoIk3VTT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best-performing model from your initial runs\n",
        "model_2.save(\"AlphabetSoupCharity_Optimization.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4AkWjy3VVuc",
        "outputId": "6cf19832-472d-4578-ba35-1939f268f161"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"AlphabetSoupCharity_Optimization.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BrphKl1h_sTF",
        "outputId": "d9193e08-5db6-44f8-b97b-63c30ce37934"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ea4700ae-c74f-4500-8e71-20a68b35b74f\", \"AlphabetSoupCharity_Optimization.h5\", 253224)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}